{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import re, gzip, os, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 路径设置\n",
    "SENT_CSV = r\"D:\\AI\\TRANSFORMER\\sentences.csv\"\n",
    "LINK_CSV = r\"D:\\AI\\TRANSFORMER\\links.csv\"\n",
    "SAVE_DIR = Path(r\"D:\\AI\\TRANSFORMER\\tatoeba_enzh_clean\")   # 输出目录\n",
    "SAVE_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 读取原始表\n",
    "print(\"Loading sentences...\")\n",
    "sent = pd.read_csv(SENT_CSV, sep=\"\\t\", header=None,\n",
    "                   names=[\"sent_id\", \"lang\", \"text\"])\n",
    "\n",
    "# 3. 抽英文和中文\n",
    "print(\"Filtering English & Chinese...\")\n",
    "en = sent[sent.lang == \"eng\"].copy()\n",
    "zh = sent[sent.lang == \"cmn\"].copy()        # Tatoeba 用 cmn 表示简体中文\n",
    "print(f\"EN: {len(en)}, ZH: {len(zh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 读取关联表\n",
    "print(\"Loading links...\")\n",
    "links = pd.read_csv(LINK_CSV, sep=\"\\t\", header=None,\n",
    "                    names=[\"left\", \"right\"])\n",
    "\n",
    "# 5. 建索引 -> 快速匹配\n",
    "en_idx = en.set_index(\"sent_id\")\n",
    "zh_idx = zh.set_index(\"sent_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# 6. 找出互为翻译的 (en_id, zh_id) 对\n",
    "pairs = []\n",
    "for row in tqdm(links.itertuples(index=False), total=len(links), desc=\"Finding EN-ZH pairs\"):\n",
    "    l, r = row.left, row.right      # 用字段名\n",
    "    if l in en_idx.index and r in zh_idx.index:\n",
    "        pairs.append((l, r))\n",
    "    elif r in en_idx.index and l in zh_idx.index:\n",
    "        pairs.append((r, l))\n",
    "\n",
    "print(f\"Raw pairs: {len(pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 转成 DataFrame\n",
    "df = pd.DataFrame(pairs, columns=[\"en_id\", \"zh_id\"])\n",
    "df[\"en\"] = df.en_id.map(en_idx.text)\n",
    "df[\"zh\"] = df.zh_id.map(zh_idx.text)\n",
    "\n",
    "# 8. 基础清洗函数\n",
    "mt_en = MosesTokenizer(lang=\"en\")\n",
    "mt_zh = MosesTokenizer(lang=\"zh\")\n",
    "def clean_en(s):\n",
    "    if pd.isna(s): return None\n",
    "    s = str(s).strip()\n",
    "    if not s: return None\n",
    "    # 去掉 html 标签、控制字符\n",
    "    s = re.sub(r\"<[^>]+>\", \"\", s)\n",
    "    s = re.sub(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]\", \"\", s)\n",
    "    # 去掉纯数字/网址/过长\n",
    "    if re.fullmatch(r\"\\d+\", s): return None\n",
    "    if \"http\" in s or \"www.\" in s: return None\n",
    "    if len(s) > 300: return None\n",
    "    return \" \".join(mt_en.tokenize(s, escape=False))\n",
    "\n",
    "def clean_zh(s):\n",
    "    if pd.isna(s): return None\n",
    "    s = str(s).strip()\n",
    "    if not s: return None\n",
    "    s = re.sub(r\"<[^>]+>\", \"\", s)\n",
    "    s = re.sub(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]\", \"\", s)\n",
    "    # 去掉纯数字/过长\n",
    "    if re.fullmatch(r\"[0-9\\s\\W]+\", s): return None\n",
    "    if len(s) > 300: return None\n",
    "    # 可选：全角转半角、统一标点\n",
    "    return \" \".join(mt_zh.tokenize(s, escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 并行清洗\n",
    "print(\"Cleaning...\")\n",
    "df[\"en_clean\"] = df.en.apply(clean_en)\n",
    "df[\"zh_clean\"] = df.zh.apply(clean_zh)\n",
    "\n",
    "# 去掉任何一边清洗后为空\n",
    "df = df.dropna(subset=[\"en_clean\", \"zh_clean\"])\n",
    "print(f\"After cleaning: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. 去重（按文本）\n",
    "df = df.drop_duplicates(subset=[\"en_clean\", \"zh_clean\"])\n",
    "print(f\"After dedup: {len(df)}\")\n",
    "\n",
    "# 11. 过滤明显质量差的\n",
    "def ratio_ok(a, b):\n",
    "    # 长度比例 1:5 ~ 5:1\n",
    "    r = len(a) / (len(b) + 1e-6)\n",
    "    return 0.2 <= r <= 5\n",
    "\n",
    "mask = df.apply(lambda x: ratio_ok(x.en_clean, x.zh_clean), axis=1)\n",
    "df = df[mask]\n",
    "print(f\"After ratio filter: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. 划分训练/验证/测试\n",
    "train, test = train_test_split(df, test_size=0.1, random_state=42)\n",
    "train, val  = train_test_split(train, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. 保存\n",
    "def save_split(split_df, name):\n",
    "    out = SAVE_DIR / f\"{name}.tsv\"\n",
    "    split_df[[\"en_clean\", \"zh_clean\"]].to_csv(out, sep=\"\\t\", index=False, header=False)\n",
    "    print(f\"{name} saved to {out}\")\n",
    "\n",
    "save_split(train, \"train\")\n",
    "save_split(val,   \"val\")\n",
    "save_split(test,  \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. 可选：BPE/Subword 词典预处理\n",
    "# -------------------------------------------------\n",
    "# 这里给出用 HuggingFace tokenizers 训练 BPE 的最小示例\n",
    "# 如果不需要可直接跳过\n",
    "if True:   # 改成 True 即可跑\n",
    "    from tokenizers import Tokenizer, models, pre_tokenizers, trainers\n",
    "    tokenizer = Tokenizer(models.BPE(unk_token=\"<unk>\"))\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "    trainer = trainers.BpeTrainer(\n",
    "        vocab_size=32000,\n",
    "        special_tokens=[\"<pad>\", \"<unk>\", \"<s>\", \"</s>\"]\n",
    "    )\n",
    "\n",
    "    files = [str(SAVE_DIR / \"train.tsv\")]\n",
    "    tokenizer.train(files, trainer)\n",
    "\n",
    "    tokenizer.save(str(SAVE_DIR / \"tokenizer.json\"))\n",
    "    print(\"BPE tokenizer saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前 5 行：\n",
      "                                                        en            zh\n",
      "0                               I don 't want to see you .       我不想看到你。\n",
      "1  As usual the peasants are busy scattering grain seeds .   農民們如常在忙著播種。\n",
      "2               He doesn 't know anything about the plan .  关于计划他什么也不知道。\n",
      "3                                Your back door was open .     你的后门是开着的。\n",
      "4                            The fire went out by itself .       火自然熄滅了。\n",
      "\n",
      "随机 5 行：\n",
      "                                  en          zh\n",
      "4491      Five plus three is eight .     五加三等於八。\n",
      "52876           No music , no life .  沒音樂 ， 沒生活。\n",
      "55981  I want to share it with you .    我想跟你分享吧。\n",
      "55934                   I hate you .        我恨你。\n",
      "51789                   I love her .        我爱她。\n",
      "\n",
      "统计信息：\n",
      "                               en       zh\n",
      "count                       56366    56366\n",
      "unique                      53234    49193\n",
      "top     I 'll help you if I can .  他要做什麼 ？\n",
      "freq                           10       16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 120)   # 让句子别被截断\n",
    "\n",
    "train = pd.read_csv(r\"D:\\AI\\TRANSFORMER\\tatoeba_enzh_clean\\train.tsv\",\n",
    "                    sep=\"\\t\", header=None, names=[\"en\", \"zh\"])\n",
    "\n",
    "print(\"前 5 行：\")\n",
    "print(train.head())\n",
    "\n",
    "print(\"\\n随机 5 行：\")\n",
    "print(train.sample(5))\n",
    "\n",
    "print(\"\\n统计信息：\")\n",
    "print(train.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPE 训练完成，已保存到 D:\\AI\\TRANSFORMER\\bpe.json\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, pre_tokenizers, trainers\n",
    "\n",
    "bpe_path = r\"D:\\AI\\TRANSFORMER\\bpe.json\"\n",
    "bpe_vocab = 32000\n",
    "\n",
    "# 1-1 准备语料文件\n",
    "with open(\"tatoeba_enzh_clean/train.tsv\", encoding=\"utf-8\") as f:\n",
    "    corpus = [line.rstrip(\"\\n\").split(\"\\t\")[0] + \" \" + line.rstrip(\"\\n\").split(\"\\t\")[1]\n",
    "              for line in f]\n",
    "\n",
    "with open(\"corpus_for_bpe.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(corpus))\n",
    "\n",
    "# 1-2 训练 BPE\n",
    "tokenizer = Tokenizer(models.BPE(unk_token=\"<unk>\"))\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "trainer = trainers.BpeTrainer(vocab_size=bpe_vocab,\n",
    "                              special_tokens=[\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"])\n",
    "tokenizer.train([\"corpus_for_bpe.txt\"], trainer)\n",
    "tokenizer.save(bpe_path)\n",
    "print(\"BPE 训练完成，已保存到\", bpe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tokenizers import Tokenizer\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子保证可复现性\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 位置编码层\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)  # (max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # (max_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                             (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)   # 偶数维\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)   # 奇数维\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, d_model)\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 带注意力追踪的编码器层\n",
    "class TransformerEncoderLayerWithTrace(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(\n",
    "            d_model, nhead, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        # src: (batch, seq, d_model)\n",
    "        src2, attn_weights = self.self_attn(\n",
    "            src, src, src,\n",
    "            attn_mask=src_mask,\n",
    "            key_padding_mask=src_key_padding_mask,\n",
    "            need_weights=True\n",
    "        )\n",
    "        src = src + self.dropout1(src2)\n",
    "        src = self.norm1(src)\n",
    "\n",
    "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        src = src + self.dropout2(src2)\n",
    "        src = self.norm2(src)\n",
    "        return src, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 微型Transformer编码器\n",
    "class TinyTransformer(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, nhead, dim_feedforward, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerEncoderLayerWithTrace(d_model, nhead, dim_feedforward, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, src, mask=None, src_key_padding_mask=None):\n",
    "        output = src\n",
    "        attn_weights_list = []\n",
    "        for layer in self.layers:\n",
    "            output, attn_weights = layer(\n",
    "                output, src_mask=mask, src_key_padding_mask=src_key_padding_mask\n",
    "            )\n",
    "            attn_weights_list.append(attn_weights)\n",
    "        return output, attn_weights_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 解码器层\n",
    "class TransformerDecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(\n",
    "            d_model, nhead, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            d_model, nhead, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n",
    "                tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        # tgt: (batch, tgt_seq, d_model) ; memory: (batch, src_seq, d_model)\n",
    "        tgt2, self_attn_weights = self.self_attn(\n",
    "            tgt, tgt, tgt,\n",
    "            attn_mask=tgt_mask,\n",
    "            key_padding_mask=tgt_key_padding_mask,\n",
    "            need_weights=True\n",
    "        )\n",
    "        tgt = tgt + self.dropout1(tgt2)\n",
    "        tgt = self.norm1(tgt)\n",
    "\n",
    "        tgt2, cross_attn_weights = self.multihead_attn(\n",
    "            tgt, memory, memory,\n",
    "            attn_mask=memory_mask,\n",
    "            key_padding_mask=memory_key_padding_mask,\n",
    "            need_weights=True\n",
    "        )\n",
    "        tgt = tgt + self.dropout2(tgt2)\n",
    "        tgt = self.norm2(tgt)\n",
    "\n",
    "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
    "        tgt = tgt + self.dropout3(tgt2)\n",
    "        tgt = self.norm3(tgt)\n",
    "        return tgt, self_attn_weights, cross_attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Transformer解码器\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, nhead, dim_feedforward, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n",
    "                tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        output = tgt\n",
    "        self_attn_list, cross_attn_list = [], []\n",
    "        for layer in self.layers:\n",
    "            output, self_attn, cross_attn = layer(\n",
    "                output, memory,\n",
    "                tgt_mask=tgt_mask, memory_mask=memory_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=memory_key_padding_mask\n",
    "            )\n",
    "            self_attn_list.append(self_attn)\n",
    "            cross_attn_list.append(cross_attn)\n",
    "        return output, self_attn_list, cross_attn_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 完整的Seq2Seq模型\n",
    "class TinyTransformerSeq2Seq(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, nhead,\n",
    "                 num_encoder_layers, num_decoder_layers, dim_feedforward,\n",
    "                 max_seq_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.src_embed = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.tgt_embed = nn.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout, max_seq_len)\n",
    "        self.pos_decoder = PositionalEncoding(d_model, dropout, max_seq_len)\n",
    "\n",
    "        self.encoder = TinyTransformer(num_encoder_layers, d_model, nhead, dim_feedforward, dropout)\n",
    "        self.decoder = TransformerDecoder(num_decoder_layers, d_model, nhead, dim_feedforward, dropout)\n",
    "\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def encode(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        # src: (batch, src_seq)\n",
    "        src_emb = self.src_embed(src) * math.sqrt(self.d_model)     # (batch, src_seq, d_model)\n",
    "        src_emb = self.pos_encoder(src_emb)\n",
    "        memory, enc_attn_weights = self.encoder(\n",
    "            src_emb, mask=src_mask, src_key_padding_mask=src_key_padding_mask\n",
    "        )\n",
    "        return memory, enc_attn_weights\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask=None, memory_mask=None,\n",
    "               tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        # tgt: (batch, tgt_seq)\n",
    "        tgt_emb = self.tgt_embed(tgt) * math.sqrt(self.d_model)     # (batch, tgt_seq, d_model)\n",
    "        tgt_emb = self.pos_decoder(tgt_emb)\n",
    "        output, self_attn, cross_attn = self.decoder(\n",
    "            tgt_emb, memory,\n",
    "            tgt_mask=tgt_mask, memory_mask=memory_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask\n",
    "        )\n",
    "        logits = self.fc_out(output)                                # (batch, tgt_seq, vocab)\n",
    "        return logits, self_attn, cross_attn\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None,\n",
    "                src_key_padding_mask=None, tgt_key_padding_mask=None):\n",
    "        memory, _ = self.encode(src, src_mask, src_key_padding_mask)\n",
    "        output, _, _ = self.decode(\n",
    "            tgt, memory, tgt_mask, None, tgt_key_padding_mask, src_key_padding_mask\n",
    "        )\n",
    "        return output  # (batch, tgt_seq, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 序列到序列数据集（处理TSV文件）\n",
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, tsv_path, tokenizer, max_len=50):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.bos_token_id = tokenizer.token_to_id(\"<bos>\")\n",
    "        self.eos_token_id = tokenizer.token_to_id(\"<eos>\")\n",
    "        self.pad_token_id = tokenizer.token_to_id(\"<pad>\")\n",
    "        self.data = []\n",
    "\n",
    "        with open(tsv_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) < 2:\n",
    "                    continue\n",
    "                en_sent = parts[0].strip()\n",
    "                zh_sent = parts[1].strip()\n",
    "\n",
    "                en_enc = tokenizer.encode(en_sent)\n",
    "                zh_enc = tokenizer.encode(zh_sent)\n",
    "\n",
    "                en_ids = [self.bos_token_id] + en_enc.ids[:max_len - 2] + [self.eos_token_id]\n",
    "                zh_ids = [self.bos_token_id] + zh_enc.ids[:max_len - 2] + [self.eos_token_id]\n",
    "\n",
    "                en_ids = en_ids + [self.pad_token_id] * (max_len - len(en_ids))\n",
    "                zh_ids = zh_ids + [self.pad_token_id] * (max_len - len(zh_ids))\n",
    "\n",
    "                self.data.append((torch.tensor(en_ids, dtype=torch.long),\n",
    "                                  torch.tensor(zh_ids, dtype=torch.long)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 生成自回归掩码\n",
    "def generate_subsequent_mask(sz):\n",
    "    # (tgt_len, tgt_len)，True 表示被mask\n",
    "    mask = torch.triu(torch.ones(sz, sz, dtype=torch.bool), diagonal=1)\n",
    "    return mask\n",
    "\n",
    "# 9. 训练函数\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, clip, device, tokenizer):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    pad_id = tokenizer.token_to_id(\"<pad>\")\n",
    "\n",
    "    for src, tgt in dataloader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        # Teacher Forcing：tgt_input 右移一位\n",
    "        tgt_input = tgt[:, :-1]                   # (batch, T-1)\n",
    "        tgt_output = tgt[:, 1:]                   # (batch, T-1)\n",
    "\n",
    "        tgt_mask = generate_subsequent_mask(tgt_input.size(1)).to(device)  # (T-1, T-1)\n",
    "        src_padding_mask = (src == pad_id)        # (batch, src_len)\n",
    "        tgt_padding_mask = (tgt_input == pad_id)  # (batch, tgt_len-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(\n",
    "            src, tgt_input,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_mask=tgt_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask\n",
    "        )  # (batch, T-1, vocab)\n",
    "\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.size(-1)),\n",
    "            tgt_output.reshape(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        if clip is not None and clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def beam_search_decode(model, src, max_len, device, tokenizer, beam_size=5):\n",
    "    model.eval()\n",
    "    src = src.unsqueeze(0).to(device) if src.dim() == 1 else src.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        memory, _ = model.encode(src)  # (1, src_len, d_model)\n",
    "\n",
    "        # 初始候选序列：[batch=1, 1]\n",
    "        bos_id = tokenizer.token_to_id(\"<bos>\")\n",
    "        eos_id = tokenizer.token_to_id(\"<eos>\")\n",
    "        sequences = [(torch.tensor([[bos_id]], device=device), 0.0)]  # (tokens, score)\n",
    "\n",
    "        for _ in range(max_len - 1):\n",
    "            all_candidates = []\n",
    "            for seq, score in sequences:\n",
    "                if seq[0, -1].item() == eos_id:\n",
    "                    # 如果已到 <eos>，直接保留\n",
    "                    all_candidates.append((seq, score))\n",
    "                    continue\n",
    "\n",
    "                tgt_mask = generate_subsequent_mask(seq.size(1)).to(device)\n",
    "                out, _, _ = model.decode(seq, memory, tgt_mask=tgt_mask)\n",
    "                prob = F.log_softmax(out[:, -1, :], dim=-1)  # log 概率\n",
    "\n",
    "                # 取 top-k\n",
    "                topk_scores, topk_ids = prob.topk(beam_size, dim=-1)\n",
    "                for i in range(beam_size):\n",
    "                    next_token = topk_ids[0, i].unsqueeze(0).unsqueeze(0)  # (1,1)\n",
    "                    new_seq = torch.cat([seq, next_token], dim=1)\n",
    "                    new_score = score + topk_scores[0, i].item()\n",
    "                    all_candidates.append((new_seq, new_score))\n",
    "\n",
    "            # 选出分数最高的 beam_size 个候选\n",
    "            ordered = sorted(all_candidates, key=lambda tup: tup[1], reverse=True)\n",
    "            sequences = ordered[:beam_size]\n",
    "\n",
    "        # 返回得分最高的序列\n",
    "        best_seq = sequences[0][0]\n",
    "    return best_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. 验证函数\n",
    "def evaluate(model, dataloader, criterion, device, tokenizer):\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    pad_id = tokenizer.token_to_id(\"<pad>\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_output = tgt[:, 1:]\n",
    "\n",
    "            tgt_mask = generate_subsequent_mask(tgt_input.size(1)).to(device)\n",
    "            src_padding_mask = (src == pad_id)\n",
    "            tgt_padding_mask = (tgt_input == pad_id)\n",
    "\n",
    "            logits = model(\n",
    "                src, tgt_input,\n",
    "                src_key_padding_mask=src_padding_mask,\n",
    "                tgt_mask=tgt_mask,\n",
    "                tgt_key_padding_mask=tgt_padding_mask\n",
    "            )\n",
    "            loss = criterion(\n",
    "                logits.reshape(-1, logits.size(-1)),\n",
    "                tgt_output.reshape(-1)\n",
    "            )\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练... 设备: cuda\n",
      "训练集大小: 56366 | 验证集大小: 6263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Train]: 100%|████████████████████████████████| 881/881 [01:07<00:00, 13.10batch/s, loss=6.638, lr=5.00e-04]\n",
      "Epoch 1/20 [Valid]: 100%|███████████████████████████████████████████████| 98/98 [00:01<00:00, 56.45batch/s, loss=6.530]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | 用时: 1分8秒\n",
      "\t训练损失: 7.082 | 验证损失: 6.662\n",
      "✓ 保存新的最佳模型，验证损失: 6.662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Train]: 100%|████████████████████████████████| 881/881 [01:36<00:00,  9.17batch/s, loss=6.549, lr=5.00e-04]\n",
      "Epoch 2/20 [Valid]: 100%|███████████████████████████████████████████████| 98/98 [00:02<00:00, 32.96batch/s, loss=6.169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | 用时: 1分39秒\n",
      "\t训练损失: 6.459 | 验证损失: 6.337\n",
      "✓ 保存新的最佳模型，验证损失: 6.337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Train]: 100%|████████████████████████████████| 881/881 [01:36<00:00,  9.16batch/s, loss=5.494, lr=5.00e-04]\n",
      "Epoch 3/20 [Valid]: 100%|███████████████████████████████████████████████| 98/98 [00:02<00:00, 32.85batch/s, loss=5.883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | 用时: 1分39秒\n",
      "\t训练损失: 6.094 | 验证损失: 6.073\n",
      "✓ 保存新的最佳模型，验证损失: 6.073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Train]: 100%|████████████████████████████████| 881/881 [01:35<00:00,  9.18batch/s, loss=5.876, lr=5.00e-04]\n",
      "Epoch 4/20 [Valid]: 100%|███████████████████████████████████████████████| 98/98 [00:02<00:00, 32.95batch/s, loss=5.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | 用时: 1分38秒\n",
      "\t训练损失: 5.730 | 验证损失: 5.828\n",
      "✓ 保存新的最佳模型，验证损失: 5.828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Train]: 100%|████████████████████████████████| 881/881 [01:44<00:00,  8.40batch/s, loss=5.304, lr=5.00e-04]\n",
      "Epoch 5/20 [Valid]: 100%|███████████████████████████████████████████████| 98/98 [00:03<00:00, 28.70batch/s, loss=5.491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | 用时: 1分48秒\n",
      "\t训练损失: 5.363 | 验证损失: 5.616\n",
      "✓ 保存新的最佳模型，验证损失: 5.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Train]: 100%|████████████████████████████████| 881/881 [01:43<00:00,  8.55batch/s, loss=4.922, lr=5.00e-04]\n",
      "Epoch 6/20 [Valid]: 100%|███████████████████████████████████████████████| 98/98 [00:03<00:00, 32.60batch/s, loss=5.334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | 用时: 1分46秒\n",
      "\t训练损失: 5.006 | 验证损失: 5.438\n",
      "✓ 保存新的最佳模型，验证损失: 5.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Train]: 100%|████████████████████████████████| 881/881 [01:42<00:00,  8.62batch/s, loss=4.655, lr=5.00e-04]\n",
      "Epoch 7/20 [Valid]: 100%|███████████████████████████████████████████████| 98/98 [00:03<00:00, 31.08batch/s, loss=5.177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | 用时: 1分45秒\n",
      "\t训练损失: 4.658 | 验证损失: 5.289\n",
      "✓ 保存新的最佳模型，验证损失: 5.289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Train]: 100%|████████████████████████████████| 881/881 [01:46<00:00,  8.30batch/s, loss=4.076, lr=5.00e-04]\n",
      "Epoch 8/20 [Valid]: 100%|███████████████████████████████████████████████| 98/98 [00:03<00:00, 30.68batch/s, loss=5.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | 用时: 1分49秒\n",
      "\t训练损失: 4.313 | 验证损失: 5.215\n",
      "✓ 保存新的最佳模型，验证损失: 5.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Train]: 100%|████████████████████████████████| 881/881 [01:46<00:00,  8.31batch/s, loss=3.906, lr=5.00e-04]\n",
      "Epoch 9/20 [Valid]: 100%|███████████████████████████████████████████████| 98/98 [00:03<00:00, 30.70batch/s, loss=5.067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | 用时: 1分49秒\n",
      "\t训练损失: 3.976 | 验证损失: 5.153\n",
      "✓ 保存新的最佳模型，验证损失: 5.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Train]: 100%|███████████████████████████████| 881/881 [01:46<00:00,  8.28batch/s, loss=3.681, lr=5.00e-04]\n",
      "Epoch 10/20 [Valid]: 100%|██████████████████████████████████████████████| 98/98 [00:03<00:00, 30.72batch/s, loss=5.045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | 用时: 1分49秒\n",
      "\t训练损失: 3.663 | 验证损失: 5.106\n",
      "✓ 保存新的最佳模型，验证损失: 5.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Train]: 100%|███████████████████████████████| 881/881 [01:44<00:00,  8.45batch/s, loss=3.346, lr=5.00e-04]\n",
      "Epoch 11/20 [Valid]: 100%|██████████████████████████████████████████████| 98/98 [00:03<00:00, 30.87batch/s, loss=5.128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | 用时: 1分47秒\n",
      "\t训练损失: 3.389 | 验证损失: 5.119\n",
      "验证集未提升：1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Train]: 100%|███████████████████████████████| 881/881 [01:47<00:00,  8.16batch/s, loss=3.207, lr=5.00e-04]\n",
      "Epoch 12/20 [Valid]: 100%|██████████████████████████████████████████████| 98/98 [00:03<00:00, 31.05batch/s, loss=5.162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | 用时: 1分51秒\n",
      "\t训练损失: 3.159 | 验证损失: 5.139\n",
      "验证集未提升：2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Train]: 100%|███████████████████████████████| 881/881 [01:47<00:00,  8.16batch/s, loss=3.043, lr=5.00e-04]\n",
      "Epoch 13/20 [Valid]: 100%|██████████████████████████████████████████████| 98/98 [00:03<00:00, 30.98batch/s, loss=5.143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | 用时: 1分51秒\n",
      "\t训练损失: 2.966 | 验证损失: 5.169\n",
      "验证集未提升：3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Train]: 100%|███████████████████████████████| 881/881 [01:51<00:00,  7.92batch/s, loss=2.686, lr=2.50e-04]\n",
      "Epoch 14/20 [Valid]: 100%|██████████████████████████████████████████████| 98/98 [00:03<00:00, 29.70batch/s, loss=5.067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | 用时: 1分54秒\n",
      "\t训练损失: 2.636 | 验证损失: 5.137\n",
      "验证集未提升：4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Train]: 100%|███████████████████████████████| 881/881 [01:44<00:00,  8.43batch/s, loss=2.448, lr=2.50e-04]\n",
      "Epoch 15/20 [Valid]: 100%|██████████████████████████████████████████████| 98/98 [00:03<00:00, 32.08batch/s, loss=5.142]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | 用时: 1分47秒\n",
      "\t训练损失: 2.513 | 验证损失: 5.176\n",
      "验证集未提升：5/5\n",
      "早停触发，结束训练。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 主函数\n",
    "if __name__ == \"__main__\":\n",
    "    # ----- 超参数 -----\n",
    "    BPE_PATH = r\"D:\\AI\\TRANSFORMER\\bpe.json\"\n",
    "    TRAIN_TSV = r\"D:\\AI\\TRANSFORMER\\tatoeba_enzh_clean\\train.tsv\"\n",
    "    VALID_TSV = r\"D:\\AI\\TRANSFORMER\\tatoeba_enzh_clean\\val.tsv\"\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 模型\n",
    "    D_MODEL = 256\n",
    "    NHEAD = 8\n",
    "    NUM_ENCODER_LAYERS = 3\n",
    "    NUM_DECODER_LAYERS = 3\n",
    "    DIM_FEEDFORWARD = 512\n",
    "    DROPOUT = 0.5          # 适度提高 Dropout（防过拟合）\n",
    "    MAX_LEN = 50\n",
    "\n",
    "    # 优化与训练\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_EPOCHS = 20\n",
    "    LR = 5e-4\n",
    "    CLIP = 1.0\n",
    "    WEIGHT_DECAY = 1e-2    # AdamW 权重衰减（防过拟合）\n",
    "    LABEL_SMOOTH = 0.1     # 标签平滑（防过拟合）\n",
    "    PATIENCE = 5           # Early Stopping 耐心\n",
    "    LR_FACTOR = 0.3        # Plateau 降学习率倍数\n",
    "    LR_PATIENCE = 2        # 几个 epoch 无提升就降 LR\n",
    "    MIN_LR = 1e-6\n",
    "\n",
    "    # ----- Tokenizer & Vocab -----\n",
    "    tokenizer = Tokenizer.from_file(BPE_PATH)\n",
    "    vocab_size = tokenizer.get_vocab_size()\n",
    "    pad_id = tokenizer.token_to_id(\"<pad>\")\n",
    "\n",
    "    # ----- 数据 -----\n",
    "    train_dataset = Seq2SeqDataset(TRAIN_TSV, tokenizer, MAX_LEN)\n",
    "    valid_dataset = Seq2SeqDataset(VALID_TSV, tokenizer, MAX_LEN)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # ----- 模型 -----\n",
    "    model = TinyTransformerSeq2Seq(\n",
    "        vocab_size, vocab_size, D_MODEL, NHEAD,\n",
    "        NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n",
    "        DIM_FEEDFORWARD, MAX_LEN, DROPOUT\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # ----- 优化器 / 调度器 / 损失 -----\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=LR_FACTOR,\n",
    "        patience=LR_PATIENCE,\n",
    "        min_lr=MIN_LR\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss(\n",
    "        ignore_index=pad_id, label_smoothing=LABEL_SMOOTH\n",
    "    )\n",
    "\n",
    "    # ----- 训练循环（含 Early Stopping）-----\n",
    "    best_valid_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    print(f\"开始训练... 设备: {DEVICE}\")\n",
    "    print(f\"训练集大小: {len(train_dataset)} | 验证集大小: {len(valid_dataset)}\")\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 训练阶段（进度条）\n",
    "        with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\", unit=\"batch\") as pbar:\n",
    "            epoch_train_loss = 0.0\n",
    "            model.train()\n",
    "            for src, tgt in pbar:\n",
    "                src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "\n",
    "                tgt_input = tgt[:, :-1]\n",
    "                tgt_output = tgt[:, 1:]\n",
    "\n",
    "                tgt_mask = generate_subsequent_mask(tgt_input.size(1)).to(DEVICE)\n",
    "                src_padding_mask = (src == pad_id)\n",
    "                tgt_padding_mask = (tgt_input == pad_id)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(\n",
    "                    src, tgt_input,\n",
    "                    src_key_padding_mask=src_padding_mask,\n",
    "                    tgt_mask=tgt_mask,\n",
    "                    tgt_key_padding_mask=tgt_padding_mask\n",
    "                )\n",
    "                loss = criterion(\n",
    "                    logits.reshape(-1, logits.size(-1)),\n",
    "                    tgt_output.reshape(-1)\n",
    "                )\n",
    "                loss.backward()\n",
    "                if CLIP is not None and CLIP > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_train_loss += loss.item()\n",
    "                pbar.set_postfix(loss=f\"{loss.item():.3f}\", lr=f\"{optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "            train_loss = epoch_train_loss / len(train_loader)\n",
    "\n",
    "        # 验证阶段（进度条）\n",
    "        with tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Valid]\", unit=\"batch\") as pbar:\n",
    "            model.eval()\n",
    "            epoch_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for src, tgt in pbar:\n",
    "                    src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "                    tgt_input = tgt[:, :-1]\n",
    "                    tgt_output = tgt[:, 1:]\n",
    "\n",
    "                    tgt_mask = generate_subsequent_mask(tgt_input.size(1)).to(DEVICE)\n",
    "                    src_padding_mask = (src == pad_id)\n",
    "                    tgt_padding_mask = (tgt_input == pad_id)\n",
    "\n",
    "                    logits = model(\n",
    "                        src, tgt_input,\n",
    "                        src_key_padding_mask=src_padding_mask,\n",
    "                        tgt_mask=tgt_mask,\n",
    "                        tgt_key_padding_mask=tgt_padding_mask\n",
    "                    )\n",
    "                    loss = criterion(\n",
    "                        logits.reshape(-1, logits.size(-1)),\n",
    "                        tgt_output.reshape(-1)\n",
    "                    )\n",
    "                    epoch_val_loss += loss.item()\n",
    "                    pbar.set_postfix(loss=f\"{loss.item():.3f}\")\n",
    "\n",
    "            valid_loss = epoch_val_loss / len(valid_loader)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(valid_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:02} | 用时: {int(epoch_mins)}分{int(epoch_secs)}秒\")\n",
    "        print(f\"\\t训练损失: {train_loss:.3f} | 验证损失: {valid_loss:.3f}\")\n",
    "\n",
    "        # 学习率调度（根据验证损失）\n",
    "        scheduler.step(valid_loss)\n",
    "\n",
    "        # Early Stopping & 保存最佳\n",
    "        if valid_loss < best_valid_loss - 1e-6:\n",
    "            best_valid_loss = valid_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), 'best_transformer_model.pt')\n",
    "            print(f\"✓ 保存新的最佳模型，验证损失: {valid_loss:.3f}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"验证集未提升：{epochs_no_improve}/{PATIENCE}\")\n",
    "            if epochs_no_improve >= PATIENCE:\n",
    "                print(\"早停触发，结束训练。\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:8: UserWarning: Glyph 35757 (\\N{CJK UNIFIED IDEOGRAPH-8BAD}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:8: UserWarning: Glyph 32451 (\\N{CJK UNIFIED IDEOGRAPH-7EC3}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:8: UserWarning: Glyph 36718 (\\N{CJK UNIFIED IDEOGRAPH-8F6E}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:8: UserWarning: Glyph 27425 (\\N{CJK UNIFIED IDEOGRAPH-6B21}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:8: UserWarning: Glyph 25439 (\\N{CJK UNIFIED IDEOGRAPH-635F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:8: UserWarning: Glyph 22833 (\\N{CJK UNIFIED IDEOGRAPH-5931}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:8: UserWarning: Glyph 39564 (\\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:8: UserWarning: Glyph 35777 (\\N{CJK UNIFIED IDEOGRAPH-8BC1}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:9: UserWarning: Glyph 35757 (\\N{CJK UNIFIED IDEOGRAPH-8BAD}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('transformer_loss_curve.png')\n",
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:9: UserWarning: Glyph 32451 (\\N{CJK UNIFIED IDEOGRAPH-7EC3}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('transformer_loss_curve.png')\n",
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:9: UserWarning: Glyph 36718 (\\N{CJK UNIFIED IDEOGRAPH-8F6E}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('transformer_loss_curve.png')\n",
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:9: UserWarning: Glyph 27425 (\\N{CJK UNIFIED IDEOGRAPH-6B21}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('transformer_loss_curve.png')\n",
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:9: UserWarning: Glyph 25439 (\\N{CJK UNIFIED IDEOGRAPH-635F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('transformer_loss_curve.png')\n",
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:9: UserWarning: Glyph 22833 (\\N{CJK UNIFIED IDEOGRAPH-5931}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('transformer_loss_curve.png')\n",
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:9: UserWarning: Glyph 39564 (\\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('transformer_loss_curve.png')\n",
      "C:\\Users\\MECHREVO\\AppData\\Local\\Temp\\ipykernel_3816\\669601303.py:9: UserWarning: Glyph 35777 (\\N{CJK UNIFIED IDEOGRAPH-8BC1}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('transformer_loss_curve.png')\n",
      "D:\\Anacon\\envs\\myenv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 35757 (\\N{CJK UNIFIED IDEOGRAPH-8BAD}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "D:\\Anacon\\envs\\myenv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 32451 (\\N{CJK UNIFIED IDEOGRAPH-7EC3}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "D:\\Anacon\\envs\\myenv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 36718 (\\N{CJK UNIFIED IDEOGRAPH-8F6E}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "D:\\Anacon\\envs\\myenv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 27425 (\\N{CJK UNIFIED IDEOGRAPH-6B21}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "D:\\Anacon\\envs\\myenv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 25439 (\\N{CJK UNIFIED IDEOGRAPH-635F}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "D:\\Anacon\\envs\\myenv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 22833 (\\N{CJK UNIFIED IDEOGRAPH-5931}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "D:\\Anacon\\envs\\myenv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 39564 (\\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "D:\\Anacon\\envs\\myenv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 35777 (\\N{CJK UNIFIED IDEOGRAPH-8BC1}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # 绘制损失曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='训练损失')\n",
    "plt.plot(val_losses, label='验证损失')\n",
    "plt.xlabel('训练轮次')\n",
    "plt.ylabel('损失')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('transformer_loss_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试翻译...\n",
      "\n",
      "样本 1:\n",
      "原文: They thought he was the son of the Sun .\n",
      "真实翻译: 他们认为 他是 太阳 之 子 。\n",
      "模型翻译: 他们 以为 他是 有 志 愿 的 ， 他 民 造 宫 的 顾客 的 ， 所以 他在 商 建 了 。\n",
      "\n",
      "自定义句子翻译测试:\n",
      "原文: Hello, how are you?\n",
      "翻译: 你好 ， 你 开着 ： “ 网络 成瘾 症 ” ， 网 已经 对 网络 是用来 实现 是用来 选 词 。\n",
      "\n",
      "原文: What is your name?\n",
      "翻译: 你 网 怎么会 这么 挫折 在 使用 中 ， 观看 时 ， 观看 发生了什么 事情 ， 观看 时 ， 观看 时 ， 观看 时 ， 有的人 轮 实现 是用来 隐藏 了 ？\n",
      "\n",
      "原文: I love learning new things.\n",
      "翻译: 我喜欢 一家 专 制 力 拉 罕 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 为了 提高 试图 为了 提高 试图 对 网络 专 专\n",
      "\n",
      "原文: The weather is beautiful today.\n",
      "翻译: 今天 天氣 經常 躺在草地上 ， 在 使用 黑暗 中 ， 所以 今天的 激 進 到 各種 各 有 虛 張 手術 。\n",
      "\n",
      "原文: This is a test of the translation system.\n",
      "翻译: 这个 网 已经 对 网络 游戏 时 ， 这个 网 译 这个 网 译 这个 网 断 这 对 网络 制 定 人们 对 网络 技术 对 网络 专 门 显示 在 网络 专 制 的 网站 的 网站 员 对 网络 专 门 对 网络 制\n",
      "\n",
      "\n",
      "样本 2:\n",
      "原文: Is your school far from your home ?\n",
      "真实翻译: 你的學校 離 你家 很遠 嗎 ?\n",
      "模型翻译: 你 上课 时 把 TATOEBA 首 合 的歌 的歌 曲 的 ， 為 不 易 年 以來 ， 有人可以 把 人類 過 在 離譜 的歌 曲 曲 曲 的 。\n",
      "\n",
      "自定义句子翻译测试:\n",
      "原文: Hello, how are you?\n",
      "翻译: 你好 ， 你 开着 ： “ 网络 成瘾 症 ” ， 网 已经 对 网络 是用来 实现 是用来 选 词 。\n",
      "\n",
      "原文: What is your name?\n",
      "翻译: 你 网 怎么会 这么 挫折 在 使用 中 ， 观看 时 ， 观看 发生了什么 事情 ， 观看 时 ， 观看 时 ， 观看 时 ， 有的人 轮 实现 是用来 隐藏 了 ？\n",
      "\n",
      "原文: I love learning new things.\n",
      "翻译: 我喜欢 一家 专 制 力 拉 罕 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 为了 提高 试图 为了 提高 试图 对 网络 专 专\n",
      "\n",
      "原文: The weather is beautiful today.\n",
      "翻译: 今天 天氣 經常 躺在草地上 ， 在 使用 黑暗 中 ， 所以 今天的 激 進 到 各種 各 有 虛 張 手術 。\n",
      "\n",
      "原文: This is a test of the translation system.\n",
      "翻译: 这个 网 已经 对 网络 游戏 时 ， 这个 网 译 这个 网 译 这个 网 断 这 对 网络 制 定 人们 对 网络 技术 对 网络 专 门 显示 在 网络 专 制 的 网站 的 网站 员 对 网络 专 门 对 网络 制\n",
      "\n",
      "\n",
      "样本 3:\n",
      "原文: I ' m definitely going to give up smoking !\n",
      "真实翻译: 我一定要 把 香 烟戒了 ！\n",
      "模型翻译: 我肯定 自己 收集 到 债 ， 我 拒绝了 ： “ 网络 成瘾 症 ” 我 所做的 是用来 接受 ， 观看 时 ， 观看 时 ， 观看 时 ， 观看 时 ， 观看 时 ， 因此 ， 我 抵抗 审 查 一个 抽象 的体 品 ！\n",
      "\n",
      "自定义句子翻译测试:\n",
      "原文: Hello, how are you?\n",
      "翻译: 你好 ， 你 开着 ： “ 网络 成瘾 症 ” ， 网 已经 对 网络 是用来 实现 是用来 选 词 。\n",
      "\n",
      "原文: What is your name?\n",
      "翻译: 你 网 怎么会 这么 挫折 在 使用 中 ， 观看 时 ， 观看 发生了什么 事情 ， 观看 时 ， 观看 时 ， 观看 时 ， 有的人 轮 实现 是用来 隐藏 了 ？\n",
      "\n",
      "原文: I love learning new things.\n",
      "翻译: 我喜欢 一家 专 制 力 拉 罕 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 为了 提高 试图 为了 提高 试图 对 网络 专 专\n",
      "\n",
      "原文: The weather is beautiful today.\n",
      "翻译: 今天 天氣 經常 躺在草地上 ， 在 使用 黑暗 中 ， 所以 今天的 激 進 到 各種 各 有 虛 張 手術 。\n",
      "\n",
      "原文: This is a test of the translation system.\n",
      "翻译: 这个 网 已经 对 网络 游戏 时 ， 这个 网 译 这个 网 译 这个 网 断 这 对 网络 制 定 人们 对 网络 技术 对 网络 专 门 显示 在 网络 专 制 的 网站 的 网站 员 对 网络 专 门 对 网络 制\n",
      "\n",
      "\n",
      "样本 4:\n",
      "原文: Search the house .\n",
      "真实翻译: 搜查 房子 。\n",
      "模型翻译: 在 找一个 高 外 的 领导 者 和 假期 里 ， 在 商 者 和 假期 中 ， 在 商 尾 酒 里 ， 在 商 员 ， 在 商 尾 酒 将 人们 在 商 员 ， 在 商 员 ， 在 商 场 。\n",
      "\n",
      "自定义句子翻译测试:\n",
      "原文: Hello, how are you?\n",
      "翻译: 你好 ， 你 开着 ： “ 网络 成瘾 症 ” ， 网 已经 对 网络 是用来 实现 是用来 选 词 。\n",
      "\n",
      "原文: What is your name?\n",
      "翻译: 你 网 怎么会 这么 挫折 在 使用 中 ， 观看 时 ， 观看 发生了什么 事情 ， 观看 时 ， 观看 时 ， 观看 时 ， 有的人 轮 实现 是用来 隐藏 了 ？\n",
      "\n",
      "原文: I love learning new things.\n",
      "翻译: 我喜欢 一家 专 制 力 拉 罕 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 为了 提高 试图 为了 提高 试图 对 网络 专 专\n",
      "\n",
      "原文: The weather is beautiful today.\n",
      "翻译: 今天 天氣 經常 躺在草地上 ， 在 使用 黑暗 中 ， 所以 今天的 激 進 到 各種 各 有 虛 張 手術 。\n",
      "\n",
      "原文: This is a test of the translation system.\n",
      "翻译: 这个 网 已经 对 网络 游戏 时 ， 这个 网 译 这个 网 译 这个 网 断 这 对 网络 制 定 人们 对 网络 技术 对 网络 专 门 显示 在 网络 专 制 的 网站 的 网站 员 对 网络 专 门 对 网络 制\n",
      "\n",
      "\n",
      "样本 5:\n",
      "原文: The moon is beautiful in fall .\n",
      "真实翻译: 秋天 的 月亮 是美丽的 。\n",
      "模型翻译: 世界上有 超過 一百 著 ， 在 商 、 M RI 和 「 隱 民 」 的 曲 」 和 超音波 。\n",
      "\n",
      "自定义句子翻译测试:\n",
      "原文: Hello, how are you?\n",
      "翻译: 你好 ， 你 开着 ： “ 网络 成瘾 症 ” ， 网 已经 对 网络 是用来 实现 是用来 选 词 。\n",
      "\n",
      "原文: What is your name?\n",
      "翻译: 你 网 怎么会 这么 挫折 在 使用 中 ， 观看 时 ， 观看 发生了什么 事情 ， 观看 时 ， 观看 时 ， 观看 时 ， 有的人 轮 实现 是用来 隐藏 了 ？\n",
      "\n",
      "原文: I love learning new things.\n",
      "翻译: 我喜欢 一家 专 制 力 拉 罕 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 试图 为了 提高 试图 为了 提高 试图 对 网络 专 专\n",
      "\n",
      "原文: The weather is beautiful today.\n",
      "翻译: 今天 天氣 經常 躺在草地上 ， 在 使用 黑暗 中 ， 所以 今天的 激 進 到 各種 各 有 虛 張 手術 。\n",
      "\n",
      "原文: This is a test of the translation system.\n",
      "翻译: 这个 网 已经 对 网络 游戏 时 ， 这个 网 译 这个 网 译 这个 网 断 这 对 网络 制 定 人们 对 网络 技术 对 网络 专 门 显示 在 网络 专 制 的 网站 的 网站 员 对 网络 专 门 对 网络 制\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # 测试翻译示例\n",
    "model.load_state_dict(torch.load('best_transformer_model.pt', map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "print(\"\\n测试翻译...\")\n",
    "\n",
    " # 从验证集取几个样本进行测试\n",
    "test_samples = random.sample(valid_dataset.data, min(5, len(valid_dataset)))\n",
    "for i, (src_ids, tgt_ids) in enumerate(test_samples):\n",
    "    src_text = tokenizer.decode(src_ids.numpy().tolist(), skip_special_tokens=True)\n",
    "    tgt_text = tokenizer.decode(tgt_ids.numpy().tolist(), skip_special_tokens=True)\n",
    "\n",
    "    translation_ids = greedy_decode(model, src_ids, MAX_LEN, DEVICE, tokenizer)\n",
    "    translation = tokenizer.decode(translation_ids[0].cpu().numpy().tolist(), skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n样本 {i+1}:\")\n",
    "    print(f\"原文: {src_text}\")\n",
    "    print(f\"真实翻译: {tgt_text}\")\n",
    "    print(f\"模型翻译: {translation}\")\n",
    "\n",
    "    # ----- 自定义句子测试 -----\n",
    "    custom_sentences = [\n",
    "        \"Hello, how are you?\",\n",
    "        \"What is your name?\",\n",
    "        \"I love learning new things.\",\n",
    "        \"The weather is beautiful today.\",\n",
    "        \"This is a test of the translation system.\"\n",
    "    ]\n",
    "    print(\"\\n自定义句子翻译测试:\")\n",
    "    for sent in custom_sentences:\n",
    "        enc = tokenizer.encode(sent)\n",
    "        src_ids = [tokenizer.token_to_id(\"<bos>\")] + enc.ids[:MAX_LEN - 2] + [tokenizer.token_to_id(\"<eos>\")]\n",
    "        src_ids = src_ids + [tokenizer.token_to_id(\"<pad>\")] * (MAX_LEN - len(src_ids))\n",
    "        src_tensor = torch.tensor(src_ids, dtype=torch.long).to(DEVICE)\n",
    "\n",
    "        translation_ids = greedy_decode(model, src_tensor, MAX_LEN, DEVICE, tokenizer)\n",
    "        translation = tokenizer.decode(translation_ids[0].cpu().numpy().tolist(), skip_special_tokens=True)\n",
    "\n",
    "        print(f\"原文: {sent}\")\n",
    "        print(f\"翻译: {translation}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
